Chapter 2 : Functional Requirements

Major functions to be handled by the software:

•   Image analysis for detection of navigation and location markers taking in
mind the navigation date received from the sensors of the AR Drone.

•   Deduction of navigation directions from navigation markers.

Detailed function:

The designated path and landmarks will be identified as follows:

•   The AR Drone will send via Wi-Fi the video feed and navigation data.

•   The computer that will receive the data will identify the pre - located 
visual
accessories using an image processing algorithms.

•   Using the Navigation data received the computer will compute the next steps
of the AR Drone

•    The Computer will send the moments command to the AR Drone via Wi-Fi.


Chapter 3 : Non Functional Requirements

•   Speed: the drone will advance at a speed of at least 0.25 m/second.

•   Checkpoint detection: detection of at least 90% of check point markers.

•   A tutorial will be written to make it easy for use to the average Joe.

•   The AR Drone path could be set in any open space (minimal obstacles) fast.

•   The code documentation will be written as clear and detailed as possible.

3.1 Performance Constraints

•   Lighting and visibility conditions: the environment must be well lit and 
there
must not be anything that might hurt visibility. Specific values TBD.

•   Battery: according to manufacturer the drone battery can last 12 minutes of
flight.

•   Safe/clear route: the path marked for the drone must be completely free of
obstacles.

•   Controlled environment: the drone must be operated in a controlled
environment, i.e. no wind/rain etc.

•   Reliability: the system is not expected to handle any kind of failure except
landing the drone safely in case of emergency.

•   Usability: the system is expected to be very usable with almost no training.
Anyone should be able to lay down navigation markers and just start the
program.


3.2    Platform constraints

3.2.1 SE Project Constraints

•   The system is not interactive. All input comes from camera/sensors built-in
the drone and to which we have full access.

•   We will not use any simulations; we will operate the actual drone.

•   The hardware required is the A.R Drone it-self and a PC with Wi-Fi.

•   Development will take place at home and at the university laboratories.

•   The final presentation (as the testing) will be performed by marking a path
and letting the drone fly along it.


Chapter 4 : Usage Scenarios

 4.1   User Proﬁles — The Actors

As we have the definition of our project to be as minimal interaction with the
humans as possible – we only have one external to the system actor and that is
the operative of the AR Drone.

Usage Scenario Number 1

1.  Name: Start-up

2.  Pre-Conditions:

a.  A Path has been marked.

b.  The drone is placed at the starting point.

3.  Steps:

a.  The user starts the program.

b.  The drone takes off.

c.  The drone detects the path markers.

d.  The drone flies along the path.

e.  The drone reaches the end of the path and lands.

4.  Exceptions:

a.  If at any point the drone doesn’t detect the path markers:

b.  The drone turns 360 degrees in attempt to locate the markers.

c.    If the marker is found the drone follows the path, otherwise it
lands.


Usage Scenario Number 2

1.  Name: Checkpoint detection

2.  Pre-Conditions:

a.  Use case “Start-up” is on-going.

3.  Steps:

a.  The drone detects a checkpoint marker.

b.  The drone sends a message to the system identifying the
checkpoint.

c.  The drone performs the callback operation received from the
system in response (currently - the drone hovers above the marker
for  a few seconds).